---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am an undergraduate currently focusing specifically in <strong>robotics</strong> in the research group of <a href='https://scholar.google.com/citations?user=dfS4ltoAAAAJ&hl=en&oi=ao'>Prof. Mengtang Li</a>. My research areas now are <strong>mechanical design</strong> and <strong>control</strong>.

<!--
My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).
-->


# üî• News
- *2025.08*: &nbsp;üé§üé§ I am honor to deliver an oral presentation in <strong>FRSE 2025</strong>.
<!--
 *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
 *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.
-->


# üìñ Educations
- *2022.09 - present*, <strong>Bachelor</strong> of Intelligent Science and Technology, the School of Intelligent Systems Engineering, <strong>Sun Yat-sen University.</strong>


# üìù Publications

[C1] <font color="#D8315B">Hongyi Chen</font>, Yicheng Chang, Puxin Yan, Minghao Wu, Mengtang Li. *novel three-finger robotic gripper with flexible belt mechanism for precision and compliant grasping*. in <strong>FRSE 2025</strong>.
<!--
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">FRSE 2025</div><img src='images/Gripper_FRSE_2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A novel three-finger robotic gripper with flexible belt mechanism for precision and compliant grasping]()

**Hongyi Chen**, Yicheng Chang, Puxin Yan, Minghao Wu, Mengtang Li

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
 -->


# üíª Internships
- *2025.07 - present*, Robot Design and Control Intern, Shenzhen MGCOOL Technology Co., Ltd., Shenzhen, China.


# <span class='anchor' id='-other'>üëÅÔ∏è‚Äçüó®Ô∏è Other</span>
<!--üëÅÔ∏è‚Äçüó®Ô∏è :eye_speech_bubble:-->

## <span class='anchor' id='-contract-bridge'>‚ô†Ô∏è‚ô•Ô∏è‚ô¶Ô∏è‚ô£Ô∏è Contract Bridge</span>
<!--‚ô†Ô∏è‚ô•Ô∏è‚ô¶Ô∏è‚ô£Ô∏è :spades::hearts::diamonds::clubs:-->
I am an enthusiast and a learner of <strong>contract bridge</strong>, which is I think the irreplaceable competitive game to sharpen memories and thinking skills and also a great release from a hectic work life. When it comes to bidding, an art form in bridge with a rich history of insights from the game's masters, the system I prefer and constantly work hard to get better at is Precision, of which the fundamentation is the book, *The Precision System of Contract Bridge Bidding*, by Charles H. Goren. I truly love how he put it then: "Precision is enjoyable, logical, and not hard to learn." And of course, it is no wonder that the system introduced originally in the 1970s has earned its place and is still played at bridge tables all over the world.
